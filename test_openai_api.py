#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯• OpenAI API å…¼å®¹æœåŠ¡å™¨
"""

import json
import time
import requests
import os

# API åŸºç¡€ URL
BASE_URL = os.environ.get("API_BASE_URL", "http://localhost:8000")

def test_health_check():
    """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    print("æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹...")
    response = requests.get(f"{BASE_URL}/health")
    
    if response.status_code == 200:
        data = response.json()
        print(f"âœ… å¥åº·æ£€æŸ¥æˆåŠŸ: {data}")
        return True
    else:
        print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code} - {response.text}")
        return False

def test_models_list():
    """æµ‹è¯•æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹"""
    print("\næµ‹è¯•æ¨¡å‹åˆ—è¡¨ç«¯ç‚¹...")
    response = requests.get(f"{BASE_URL}/v1/models")
    
    if response.status_code == 200:
        data = response.json()
        print("âœ… æ¨¡å‹åˆ—è¡¨è·å–æˆåŠŸ:")
        for model in data.get("data", []):
            print(f"  - {model['id']} (owned by: {model['owned_by']})")
        return True
    else:
        print(f"âŒ æ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥: {response.status_code} - {response.text}")
        return False

def test_chat_completion():
    """æµ‹è¯•èŠå¤©å®Œæˆç«¯ç‚¹"""
    print("\næµ‹è¯•èŠå¤©å®Œæˆç«¯ç‚¹...")
    
    # æµ‹è¯•æ•°æ®
    payload = {
        "model": "gpt-3.5-turbo",
        "messages": [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
        ],
        "temperature": 0.7,
        "max_tokens": 1000
    }
    
    response = requests.post(
        f"{BASE_URL}/v1/chat/completions",
        headers={"Content-Type": "application/json"},
        json=payload
    )
    
    if response.status_code == 200:
        data = response.json()
        print("âœ… èŠå¤©å®ŒæˆæˆåŠŸ:")
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        print(f"  æ¨¡å‹: {data.get('model')}")
        print(f"  å›å¤: {content[:100]}..." if len(content) > 100 else f"  å›å¤: {content}")
        return True
    else:
        print(f"âŒ èŠå¤©å®Œæˆå¤±è´¥: {response.status_code} - {response.text}")
        return False

def test_chat_completion_with_gpt4():
    """æµ‹è¯•ä½¿ç”¨ GPT-4 æ¨¡å‹çš„èŠå¤©å®Œæˆç«¯ç‚¹"""
    print("\næµ‹è¯• GPT-4 æ¨¡å‹èŠå¤©å®Œæˆç«¯ç‚¹...")
    
    # æµ‹è¯•æ•°æ®
    payload = {
        "model": "gpt-4",
        "messages": [
            {"role": "user", "content": "ç°åœ¨ä½ æ˜¯é»‘çŒ«æ¨¡å‹å—ï¼Ÿ"}
        ],
        "temperature": 0.7
    }
    
    response = requests.post(
        f"{BASE_URL}/v1/chat/completions",
        headers={"Content-Type": "application/json"},
        json=payload
    )
    
    if response.status_code == 200:
        data = response.json()
        print("âœ… GPT-4 èŠå¤©å®ŒæˆæˆåŠŸ:")
        content = data.get("choices", [{}])[0].get("message", {}).get("content", "")
        print(f"  æ¨¡å‹: {data.get('model')}")
        print(f"  å›å¤: {content[:100]}..." if len(content) > 100 else f"  å›å¤: {content}")
        return True
    else:
        print(f"âŒ GPT-4 èŠå¤©å®Œæˆå¤±è´¥: {response.status_code} - {response.text}")
        return False

def test_streaming_chat_completion():
    """æµ‹è¯•æµå¼èŠå¤©å®Œæˆç«¯ç‚¹"""
    print("\næµ‹è¯•æµå¼èŠå¤©å®Œæˆç«¯ç‚¹...")
    
    # æµ‹è¯•æ•°æ®
    payload = {
        "model": "gpt-3.5-turbo",
        "messages": [
            {"role": "user", "content": "è¯·ç”¨æµå¼å›å¤ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"}
        ],
        "temperature": 0.7,
        "stream": True
    }
    
    response = requests.post(
        f"{BASE_URL}/v1/chat/completions",
        headers={"Content-Type": "application/json"},
        json=payload,
        stream=True
    )
    
    if response.status_code == 200:
        print("âœ… æµå¼èŠå¤©å®ŒæˆæˆåŠŸ:")
        full_content = ""
        for line in response.iter_lines():
            if line:
                line = line.decode('utf-8')
                if line.startswith("data: "):
                    data_str = line[6:]
                    if data_str == "[DONE]":
                        break
                    try:
                        data = json.loads(data_str)
                        if "choices" in data and len(data["choices"]) > 0:
                            delta = data["choices"][0].get("delta", {})
                            if "content" in delta and delta["content"]:
                                content = delta["content"]
                                full_content += content
                                print(content, end="", flush=True)
                    except json.JSONDecodeError:
                        pass
        print(f"\nå®Œæ•´å›å¤é•¿åº¦: {len(full_content)} å­—ç¬¦")
        return True
    else:
        print(f"âŒ æµå¼èŠå¤©å®Œæˆå¤±è´¥: {response.status_code} - {response.text}")
        return False

def test_sessions():
    """æµ‹è¯•ä¼šè¯ç®¡ç†ç«¯ç‚¹"""
    print("\næµ‹è¯•ä¼šè¯ç®¡ç†ç«¯ç‚¹...")
    
    # è·å–ä¼šè¯åˆ—è¡¨
    response = requests.get(f"{BASE_URL}/sessions")
    
    if response.status_code == 200:
        data = response.json()
        print("âœ… ä¼šè¯åˆ—è¡¨è·å–æˆåŠŸ:")
        for session in data.get("sessions", []):
            print(f"  - ä¼šè¯ ID: {session['id']}")
            print(f"    æ¨¡å‹: {session['model']}")
            print(f"    åˆ›å»ºæ—¶é—´: {session['created_at']}")
            print(f"    æœ‰ AnuNeko ä¼šè¯: {session['has_anuneko_chat']}")
        return True
    else:
        print(f"âŒ ä¼šè¯åˆ—è¡¨è·å–å¤±è´¥: {response.status_code} - {response.text}")
        return False

def test_openai_client():
    """ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯åº“æµ‹è¯•"""
    print("\nä½¿ç”¨ OpenAI å®¢æˆ·ç«¯åº“æµ‹è¯•...")
    
    try:
        from openai import OpenAI
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        client = OpenAI(
            api_key="dummy-key",  # ä¸éœ€è¦çœŸå®çš„ key
            base_url=f"{BASE_URL}/v1"
        )
        
        # æµ‹è¯•èŠå¤©å®Œæˆ
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼Œä½¿ç”¨ OpenAI å®¢æˆ·ç«¯åº“æµ‹è¯•"}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        print("âœ… OpenAI å®¢æˆ·ç«¯åº“æµ‹è¯•æˆåŠŸ:")
        print(f"  æ¨¡å‹: {response.model}")
        print(f"  å›å¤: {response.choices[0].message.content}")
        return True
    
    except ImportError:
        print("âš ï¸ æœªå®‰è£… OpenAI å®¢æˆ·ç«¯åº“ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
        print("   å®‰è£…å‘½ä»¤: pip install openai")
        return True
    except Exception as e:
        print(f"âŒ OpenAI å®¢æˆ·ç«¯åº“æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹æµ‹è¯• OpenAI API å…¼å®¹æœåŠ¡å™¨...\n")
    
    tests = [
        test_health_check,
        test_models_list,
        test_chat_completion,
        test_chat_completion_with_gpt4,
        test_streaming_chat_completion,
        test_sessions,
        test_openai_client
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
            time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {str(e)}")
    
    print(f"\næµ‹è¯•å®Œæˆ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€")

if __name__ == "__main__":
    main()